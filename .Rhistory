# Modelo 1: Baseline (independência)
cat("Ajustando Modelo 1: Baseline (independência)...\n")
try({
fit1_air <- mcglm(
linear_pred = linear_preds,
matrix_pred = rep(list(Z0), length(linear_preds)),
link = rep("log", length(linear_preds)),
variance = rep("tweedie", length(linear_preds)),
power_fixed = rep(FALSE, length(linear_preds)),
control_algorithm = list(max_iter = 100, verbose = FALSE, tuning = 0.5),
data = mcglm_data
)
cat("Modelo 1 ajustado com sucesso!\n")
model1_success <- TRUE
}, silent = FALSE)
fit1_air <- mcglm(
linear_pred = linear_preds,
matrix_pred = rep(list(Z0), length(linear_preds)),
link = rep("log", length(linear_preds)),
variance = rep("tweedie", length(linear_preds)),
power_fixed = rep(FALSE, length(linear_preds)),
control_algorithm = list(max_iter = 100, verbose = FALSE, tuning = 0.5),
data = mcglm_data
)
linear_preds
rep(list(Z0), length(linear_preds))
rep("tweedie", length(linear_preds))
rep(FALSE, length(linear_preds))
mcglm_data
dim(as.data.frame(mcglm_data))
fit1_air <- mcglm(
linear_pred = linear_preds,
matrix_pred = rep(list(Z0), length(linear_preds)),
link = rep("log", length(linear_preds)),
variance = rep("tweedie", length(linear_preds)),
power_fixed = rep(FALSE, length(linear_preds)),
control_algorithm = list(max_iter = 100, verbose = FALSE, tuning = 0.5),
data = as.data.frame(mcglm_data)
)
fit1_air <- mcglm(
linear_pred = linear_preds,
matrix_pred = rep(list(Z0), length(linear_preds)),
link = rep("log", length(linear_preds)),
variance = rep("tweedie", length(linear_preds)),
power_fixed = rep(FALSE, length(linear_preds)),
control_algorithm = list(max_iter = 100, verbose = FALSE, tuning = 0.5),
data = as.data.frame(mcglm_data)
)
cat("Modelo 1 ajustado com sucesso!\n")
fit1_air <- mcglm(
linear_pred = linear_preds,
matrix_pred = rep(list(Z0), length(linear_preds)),
link = rep("log", length(linear_preds)),
variance = rep("tweedie", length(linear_preds)),
power_fixed = rep(FALSE, length(linear_preds)),
control_algorithm = list(max_iter = 100, verbose = FALSE, tuning = 0.5),
data = as.data.frame(mcglm_data)
)
fit1_air <- mcglm(
linear_pred = linear_preds,
matrix_pred = rep(list(Z0), length(linear_preds)),
link = rep("log", length(linear_preds)),
variance = rep("constant", length(linear_preds)),
control_algorithm = list(max_iter = 50, verbose = FALSE),
data = mcglm_data
)
# Modelo 2: Com estrutura temporal
fit2_air <- mcglm(
linear_pred = linear_preds,
matrix_pred = rep(list(c(Z0, Z_ma1)), length(linear_preds)),
link = rep("log", length(linear_preds)),
variance = rep("tweedie", length(linear_preds)),
power_fixed = rep(TRUE, length(linear_preds)),  # Fixar para estabilidade
control_algorithm = list(max_iter = 100, verbose = FALSE, tuning = 0.3),
data = mcglm_data
)
linear_preds
str(mcglm_data)
T_std + RH_std + Hour_f + Season_f + DayType_f
# Modelo 2: Com estrutura temporal
fit2_air <- mcglm(
linear_pred = linear_preds,
matrix_pred = rep(list(c(Z0, Z_ma1)), length(linear_preds)),
link = rep("log", length(linear_preds)),
variance = rep("tweedie", length(linear_preds)),
power_fixed = rep(TRUE, length(linear_preds)),  # Fixar para estabilidade
control_algorithm = list(max_iter = 100, verbose = FALSE, tuning = 0.3),
data = mcglm_data
)
# Modelo 3: Estrutura completa (se possível)
fit3_air <- mcglm(
linear_pred = linear_preds,
matrix_pred = rep(list(c(Z0, Z_ma1, Z_seasonal)), length(linear_preds)),
link = rep("log", length(linear_preds)),
variance = rep("tweedie", length(linear_preds)),
power_fixed = rep(TRUE, length(linear_preds)),
control_algorithm = list(max_iter = 150, verbose = FALSE, tuning = 0.3),
data = mcglm_data
)
# Carregamento de bibliotecas necessárias
library(mcglm)
library(tidyverse)
library(MASS)
library(survival)
library(lattice)
library(corrplot)
library(mice)
library(nlme)
library(ggplot2)
library(Matrix)
cat("=== INICIANDO ANÁLISE CARDIA LONGITUDINAL COM MCGLM ===\n")
mc_ma2 <- function(id, time, data, order = 1) {
# Função auxiliar para criar matriz de correlação MA
mc_ma_aux <- function(n, order) {
# Verifica se order é válido
if (order >= n) {
warning("Order deve ser menor que o número de observações. Ajustando para n-1.")
order <- max(1, n - 1)
}
# Cria matriz identidade como base
mat <- Matrix::Diagonal(n)
# Adiciona bandas para correlação temporal
for (k in 1:order) {
# Banda superior
if (k < n) {
upper_diag <- rep(1, n - k)
mat <- mat + Matrix::bandSparse(n, n, k = k, diagonals = list(upper_diag))
}
# Banda inferior (para simetria)
if (k < n) {
lower_diag <- rep(1, n - k)
mat <- mat + Matrix::bandSparse(n, n, k = -k, diagonals = list(lower_diag))
}
return(mat)
}
# Validações iniciais
if (!all(c(id, time) %in% names(data))) {
stop("Variáveis 'id' e/ou 'time' não encontradas nos dados.")
}
# Preserva índices originais
data$original_index <- seq_len(nrow(data))
# Ordena dados por ID e tempo
data_ordered <- data[order(data[[id]], data[[time]]), ]
# Divide dados por ID
data_split <- split(data_ordered, data_ordered[[id]], drop = TRUE)
# Verifica se todos os grupos têm o mesmo número de observações
group_sizes <- sapply(data_split, nrow)
if (length(unique(group_sizes)) > 1) {
stop("Modelo requer número igual de observações por ID. ",
"Tamanhos encontrados: ", paste(unique(group_sizes), collapse = ", "))
}
# Constrói matrizes de correlação por grupo
Z1_list <- vector("list", length(data_split))
names(Z1_list) <- names(data_split)
for (i in seq_along(data_split)) {
group_data <- data_split[[i]]
n_obs <- nrow(group_data)
# Ajusta order se necessário
current_order <- min(order, n_obs - 1)
if (current_order != order) {
warning(sprintf("Grupo %s: order ajustado de %d para %d devido ao tamanho do grupo (%d obs)",
names(data_split)[i], order, current_order, n_obs))
}
# Cria matriz de correlação temporal
Z1_list[[i]] <- mc_ma_aux(n_obs, current_order)
}
# Combina matrizes em estrutura block-diagonal
Z1_combined <- Matrix::bdiag(Z1_list)
# Reordena para corresponder à ordem original dos dados
reorder_indices <- order(data_ordered$original_index)
Z1_final <- Z1_combined[reorder_indices, reorder_indices]
# Retorna resultado
list(
Z1 = Z1_final,
info = list(
n_groups = length(data_split),
group_sizes = group_sizes,
total_obs = nrow(data),
order_used = order,
group_names = names(data_split)
)
}
cat("\n=== SIMULAÇÃO DE DADOS CARDIA-LIKE ===\n")
set.seed(42)
# Parâmetros baseados no estudo CARDIA real
n_subjects <- 800    # Número de participantes
n_visits_max <- 8    # Máximo de visitas
visit_years <- c(0, 2, 5, 7, 10, 15, 20, 25)
# Função para simular dados longitudinais realistas
simulate_cardia_data <- function(n_subjects, visit_years) {
# Características basais dos participantes
baseline <- tibble(
subject_id = 1:n_subjects,
age_baseline = runif(n_subjects, 18, 30),
gender = sample(c("Male", "Female"), n_subjects, replace = TRUE),
race = sample(c("White", "Black"), n_subjects, replace = TRUE, prob = c(0.55, 0.45)),
education = sample(c("High School", "College", "Graduate"), n_subjects,
replace = TRUE, prob = c(0.35, 0.45, 0.20)),
family_history_cvd = rbinom(n_subjects, 1, 0.30),
baseline_income = exp(rnorm(n_subjects, log(45000), 0.6)),
# Efeitos aleatórios individuais (persistentes ao longo do tempo)
re_sbp = rnorm(n_subjects, 0, 12),
re_bmi = rnorm(n_subjects, 0, 2.5),
re_risk = rnorm(n_subjects, 0, 0.8)
)
# Expandir para estrutura longitudinal
data_long <- baseline %>%
slice(rep(1:n(), each = length(visit_years))) %>%
mutate(
visit = rep(1:length(visit_years), n_subjects),
year = rep(visit_years, n_subjects),
age = age_baseline + year
)
# Simulação de trajetórias realistas com efeitos longitudinais
data_complete <- data_long %>%
mutate(
# Smoking status (tende a diminuir com idade e varia por demografia)
smoking_prob = pmax(0.08, 0.45 - 0.012 * age +
ifelse(gender == "Male", 0.08, 0) +
ifelse(race == "Black", 0.03, 0) +
ifelse(education == "High School", 0.10,
ifelse(education == "Graduate", -0.08, 0))),
smoking = rbinom(n(), 1, smoking_prob),
# Physical activity (diminui com idade, varia por gênero)
exercise_hours = pmax(0, rnorm(n(), 6.5 - 0.08 * age +
ifelse(gender == "Male", 1.2, 0) +
ifelse(education == "Graduate", 1.0, 0), 2.5)),
# BMI (trajetória realística: aumenta com idade)
bmi_linear = 21.5 + 0.18 * age + re_bmi +
ifelse(gender == "Male", 1.2, 0) +
ifelse(race == "Black", 2.0, 0) +
smoking * (-0.8) +
ifelse(education == "Graduate", -0.8, 0) +
exercise_hours * (-0.15),
bmi = pmax(16, bmi_linear + rnorm(n(), 0, 1.2)),
# Systolic Blood Pressure (aumenta com idade, BMI, e outros fatores)
sbp_linear = 108 + 0.85 * age + 0.65 * bmi + re_sbp +
ifelse(gender == "Male", 6, 0) +
ifelse(race == "Black", 12, 0) +
smoking * 4 +
family_history_cvd * 7 +
exercise_hours * (-0.5),
sbp = pmax(85, sbp_linear + rnorm(n(), 0, 10)),
# Total Cholesterol
total_chol = 155 + 1.5 * age + 0.35 * bmi +
ifelse(gender == "Male", 8, 0) +
smoking * 6 +
exercise_hours * (-0.8) +
rnorm(n(), 0, 22),
# HDL Cholesterol
hdl_chol = 58 - 0.15 * age - 0.12 * bmi +
ifelse(gender == "Female", 12, 0) +
exercise_hours * 0.6 - smoking * 4 +
rnorm(n(), 0, 9),
# Glucose levels
glucose = 82 + 0.4 * age + 0.45 * bmi +
ifelse(family_history_cvd == 1, 6, 0) +
ifelse(race == "Black", 3, 0) +
rnorm(n(), 0, 12),
# Definir condições baseadas em critérios clínicos
hypertension = ifelse(sbp >= 140, 1, 0),
diabetes = ifelse(glucose >= 126, 1, 0),
obesity = ifelse(bmi >= 30, 1, 0),
high_chol = ifelse(total_chol >= 240, 1, 0),
low_hdl = ifelse((gender == "Male" & hdl_chol < 40) |
(gender == "Female" & hdl_chol < 50), 1, 0),
# Contagem de fatores de risco cardiovascular (0-5)
risk_factors_count = hypertension + diabetes + smoking + obesity + low_hdl,
# CVD Events (usando modelo de risco baseado em fatores conhecidos)
cvd_risk_linear = -4.5 + 0.05 * age + 0.008 * sbp +
0.6 * diabetes + 0.4 * smoking +
0.35 * family_history_cvd +
0.15 * obesity + re_risk * 0.1,
cvd_prob_annual = plogis(cvd_risk_linear) * 0.002,  # Probabilidade anual baixa
# Variáveis para análise temporal
time_since_baseline = year,
age_centered = age - mean(age, na.rm = TRUE),
bmi_centered = bmi - mean(bmi, na.rm = TRUE)
) %>%
group_by(subject_id) %>%
arrange(year) %>%
mutate(
# CVD events (cumulativo - uma vez que ocorre, persiste)
cvd_event_this_visit = rbinom(n(), 1, cvd_prob_annual),
cvd_event = as.numeric(cumsum(cvd_event_this_visit) > 0),
# Padrão realístico de dropout
dropout_prob = 0.03 + 0.004 * visit +
ifelse(cvd_event == 1, 0.08, 0) +
ifelse(age > 45, 0.02, 0),
observed = rbinom(n(), 1, 1 - dropout_prob),
# Lag variables para capturar efeitos temporais
sbp_lag1 = lag(sbp, 1),
bmi_lag1 = lag(bmi, 1)
) %>%
ungroup() %>%
filter(observed == 1) %>%  # Remover dropouts
dplyr::select(-dropout_prob, -observed, -smoking_prob, -cvd_risk_linear,
-cvd_prob_annual, -cvd_event_this_visit)
return(data_complete)
}
# Gerar dados
cardia_data <- simulate_cardia_data(n_subjects, visit_years)
cat("Dados simulados - Dimensões:", dim(cardia_data), "\n")
cat("Participantes únicos:", length(unique(cardia_data$subject_id)), "\n")
cat("Visitas por participante (média):",
round(nrow(cardia_data) / length(unique(cardia_data$subject_id)), 1), "\n")
cat("\n=== ANÁLISE EXPLORATÓRIA LONGITUDINAL ===\n")
# Resumo por visita
summary_by_visit <- cardia_data %>%
group_by(year) %>%
summarise(
n = n(),
retention_rate = round(n / n_subjects * 100, 1),
mean_age = round(mean(age), 1),
mean_sbp = round(mean(sbp), 1),
mean_bmi = round(mean(bmi), 1),
obesity_rate = round(mean(obesity) * 100, 1),
cvd_rate = round(mean(cvd_event) * 100, 1),
mean_risk_count = round(mean(risk_factors_count), 2),
.groups = 'drop'
)
cat("Resumo longitudinal por ano:\n")
print(summary_by_visit)
# Correlações entre variáveis resposta (baseline)
baseline_data <- cardia_data %>% filter(year == 0)
response_vars <- c("sbp", "obesity", "risk_factors_count")
baseline_corr <- baseline_data[response_vars] %>%
cor(use = "complete.obs")
cat("\nCorrelações entre variáveis resposta (baseline):\n")
print(round(baseline_corr, 3))
# Distribuições por demografia
demo_summary <- baseline_data %>%
group_by(gender, race) %>%
summarise(
n = n(),
mean_sbp = round(mean(sbp), 1),
mean_bmi = round(mean(bmi), 1),
obesity_rate = round(mean(obesity) * 100, 1),
.groups = 'drop'
)
cat("\nCaracterísticas basais por demografia:\n")
print(demo_summary)
# Visualização de trajetórias (amostra)
trajectory_sample <- cardia_data %>%
filter(subject_id %in% sample(unique(subject_id), min(50, length(unique(subject_id))))) %>%
dplyr::select(subject_id, year, sbp, bmi, risk_factors_count) %>%
pivot_longer(cols = c(sbp, bmi, risk_factors_count),
names_to = "variable", values_to = "value")
trajectory_plot <- ggplot(trajectory_sample, aes(x = year, y = value, group = subject_id)) +
geom_line(alpha = 0.4, color = "lightblue") +
geom_smooth(method = "loess", se = TRUE, color = "red", linewidth = 1.2, aes(group = 1)) +
facet_wrap(~variable, scales = "free_y") +
labs(title = "Longitudinal Trajectories of Cardiovascular Variables (Sample)",
x = "Years from Baseline", y = "Value") +
theme_minimal()
print(trajectory_plot)
cat("\n=== PREPARAÇÃO PARA MCGLM ===\n")
# Preparar dados para análise mcglm
mcglm_data <- cardia_data %>%
mutate(
# Variáveis categóricas
subject_f = factor(subject_id),
gender_f = factor(gender),
race_f = factor(race),
education_f = factor(education),
visit_f = factor(visit),
# Variáveis padronizadas para melhor convergência
age_std = as.numeric(scale(age)),
exercise_std = as.numeric(scale(exercise_hours)),
income_std = as.numeric(scale(log(baseline_income + 1))),
# Interações importantes
age_gender = age_std * (gender == "Male"),
age_race = age_std * (race == "Black"),
# Transformações para melhorar ajuste
sbp_scaled = sbp / 10,  # Escalar para melhorar convergência numérica
risk_count_plus1 = risk_factors_count + 1  # Evitar zeros na regressão Poisson
) %>%
arrange(subject_id, year) %>%
filter(!is.na(sbp) & !is.na(obesity) & !is.na(risk_factors_count))
cat("Dados preparados para mcglm:\n")
cat("- Dimensões:", dim(mcglm_data), "\n")
cat("- Participantes únicos:", length(unique(mcglm_data$subject_id)), "\n")
cat("- Range de SBP:", range(mcglm_data$sbp), "\n")
cat("- Taxa de obesidade:", round(mean(mcglm_data$obesity) * 100, 1), "%\n")
cat("- Range de fatores de risco:", range(mcglm_data$risk_factors_count), "\n")
# Verificar balanceamento
cat("\nDistribuição por gênero e raça:\n")
print(table(mcglm_data$gender_f, mcglm_data$race_f))
cat("\n=== ESPECIFICAÇÃO DOS MODELOS MCGLM ===\n")
# Preditores lineares para os três tipos de resposta
# 1. SBP (contínua) - normal/tweedie com link identity
form_sbp <- sbp_scaled ~ age_std + gender_f + race_f + education_f +
exercise_std + smoking + family_history_cvd
# 2. Obesity (binária) - binomial com link logit
form_obesity <- obesity ~ age_std + gender_f + race_f + education_f +
exercise_std + smoking + family_history_cvd
# 3. Risk Factors Count (contagem) - Poisson/NB com link log
form_risk <- risk_count_plus1 ~ age_std + gender_f + race_f + education_f +
exercise_std + income_std + family_history_cvd
cat("Fórmulas especificadas:\n")
cat("- SBP (contínua):", deparse(form_sbp), "\n")
cat("- Obesidade (binária):", deparse(form_obesity), "\n")
cat("- Fatores de risco (contagem):", deparse(form_risk), "\n")
# Construir componentes da matriz linear para estrutura longitudinal
cat("\nConstruindo estruturas de covariância longitudinal...\n")
# Matriz identidade (efeito residual)
Z0 <- mc_id(mcglm_data)
# Efeito aleatório de participante (compound symmetry)
Z_subject <- mc_mixed(~ 0 + subject_f, data = mcglm_data)
# Estrutura temporal dentro do participante
# Criar estrutura MA(1) para capturar dependência temporal
Z_ma <- mc_ma2(id = "subject_id", time = "visit", data = mcglm_data, order = 1)
unique(mcglm_data$subject_f)
unique(table(mcglm_data$subject_f))
table(mcglm_data$subject_f)
cat("Estruturas de covariância construídas:\n")
cat("- Z0 (identidade):", length(Z0), "componente(s)\n")
cat("- Z_subject (efeito aleatório):", length(Z_subject), "componente(s)\n")
cat("- Z_ma (temporal MA1):", length(Z_ma), "componente(s)\n")
cat("\n=== AJUSTE SEQUENCIAL DOS MODELOS MCGLM ===\n")
# Modelo 1: Independência (baseline)
cat("Modelo 1: Assumindo independência entre observações...\n")
try({
fit1_cardia <- mcglm(
linear_pred = c(form_sbp, form_obesity, form_risk),
matrix_pred = list(Z0, Z0, Z0),
link = c("identity", "logit", "log"),
variance = c("constant", "binomialP", "poisson_tweedie"),
power_fixed = c(TRUE, TRUE, TRUE),  # Fixar para estabilidade inicial
Ntrial = list(NULL, rep(1, nrow(mcglm_data)), NULL),
control_algorithm = list(max_iter = 100, verbose = FALSE, tuning = 0.5),
data = mcglm_data
)
cat("✓ Modelo 1 ajustado com sucesso!\n")
model1_success <- TRUE
}, silent = FALSE)
require(Matrix)
try({
fit1_cardia <- mcglm(
linear_pred = c(form_sbp, form_obesity, form_risk),
matrix_pred = list(Z0, Z0, Z0),
link = c("identity", "logit", "log"),
variance = c("constant", "binomialP", "poisson_tweedie"),
power_fixed = c(TRUE, TRUE, TRUE),  # Fixar para estabilidade inicial
Ntrial = list(NULL, rep(1, nrow(mcglm_data)), NULL),
control_algorithm = list(max_iter = 100, verbose = FALSE, tuning = 0.5),
data = mcglm_data
)
cat("✓ Modelo 1 ajustado com sucesso!\n")
model1_success <- TRUE
}, silent = FALSE)
fit1_cardia
# Modelo 1: Independência (baseline)
fit1_cardia <- mcglm(
linear_pred = c(form_sbp, form_obesity, form_risk),
matrix_pred = list(Z0, Z0, Z0),
link = c("identity", "logit", "log"),
variance = c("constant", "binomialP", "poisson_tweedie"),
power_fixed = c(TRUE, TRUE, TRUE),  # Fixar para estabilidade inicial
Ntrial = list(NULL, rep(1, nrow(mcglm_data)), NULL),
control_algorithm = list(max_iter = 100, verbose = FALSE, tuning = 0.5),
data = mcglm_data
)
# Modelo 2: Com efeito aleatório de participante
fit2_cardia <- mcglm(
linear_pred = c(form_sbp, form_obesity, form_risk),
matrix_pred = list(c(Z0, Z_subject), c(Z0, Z_subject), c(Z0, Z_subject)),
link = c("identity", "logit", "log"),
variance = c("constant", "binomialP", "poisson_tweedie"),
power_fixed = c(TRUE, TRUE, FALSE),  # Permitir estimação de power para Poisson-Tweedie
Ntrial = list(NULL, rep(1, nrow(mcglm_data)), NULL),
control_algorithm = list(max_iter = 200, verbose = FALSE, tuning = 0.3),
data = mcglm_data
)
fit2_cardia
# Modelo 3: Estrutura longitudinal completa
fit3_cardia <- mcglm(
linear_pred = c(form_sbp, form_obesity, form_risk),
matrix_pred = list(c(Z0, Z_subject, Z_ma),
c(Z0, Z_subject, Z_ma),
c(Z0, Z_subject, Z_ma)),
link = c("identity", "logit", "log"),
variance = c("constant", "binomialP", "poisson_tweedie"),
power_fixed = c(TRUE, TRUE, FALSE),
Ntrial = list(NULL, rep(1, nrow(mcglm_data)), NULL),
control_algorithm = list(max_iter = 250, verbose = FALSE, tuning = 0.2),
data = mcglm_data
)
# Coletar modelos ajustados
fitted_models <- list()
model_names <- character()
setwd("~/Dropbox/UFPR/Doutorado/Artigos/gkwreg-joss/Lopes")
# Carregue o pacote
library(rmarkdown)
caminho_arquivo_rmd <- "Lopes.Rmd"
render(caminho_arquivo_rmd, output_format = "markdown")
?render
# Carregue o pacote
library(rmarkdown)
caminho_arquivo_rmd <- "paper.Rmd"
render(caminho_arquivo_rmd, output_format = "paper.md")
render(caminho_arquivo_rmd, output_format = "md")
?render
# Carregue o pacote
library(rmarkdown)
caminho_arquivo_rmd <- "paper.Rmd"
render(caminho_arquivo_rmd, output_format = "all")
caminho_arquivo_rmd <- "paper.Rmd"
# Carregue o pacote
library(rmarkdown)
caminho_arquivo_rmd <- "paper.Rmd"
render(caminho_arquivo_rmd, output_format = "all")
